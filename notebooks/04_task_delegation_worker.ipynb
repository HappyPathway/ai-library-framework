{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Delegation with a Worker for Prompt Refinement\n",
    "\n",
    "This notebook demonstrates a pattern where an \"Initial Agent\" delegates a sub-task to a \"Task Worker.\" The Task Worker uses its own AI engine to perform meaningful prompting (e.g., refining a query, generating context, or suggesting improvements). The worker's output is then returned to the Initial Agent, which uses it to build a better, more detailed prompt for its primary task execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import necessary libraries and AILF components. This includes `AIEngine` for interacting with LLMs, Pydantic for data validation, and other standard Python libraries. We'll also load environment variables for API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Dict, Any, List, Optional\n",
    "from pprint import pprint\n",
    "\n",
    "# Pydantic for data modeling\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# AILF framework components\n",
    "from ailf.ai.engine import AIEngine # Assuming AIEngine is in this path\n",
    "from ailf.schemas.ai import AIConfig # Assuming AIConfig is in this path\n",
    "\n",
    "# Load environment variables (for API keys)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API keys (OpenAI and Anthropic)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "api_keys_available = {\n",
    "    \"openai\": bool(OPENAI_API_KEY),\n",
    "    \"anthropic\": bool(ANTHROPIC_API_KEY)\n",
    "}\n",
    "\n",
    "print(\"API Keys Available:\")\n",
    "for api, available in api_keys_available.items():\n",
    "    print(f\"- {api.upper()}: {'âœ“' if available else 'âœ—'}\")\n",
    "\n",
    "if not any(api_keys_available.values()):\n",
    "    print(\"\\nWarning: No API keys found. LLM calls will fail.\")\n",
    "    print(\"Please set up your .env file with OPENAI_API_KEY or ANTHROPIC_API_KEY.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function to Create AI Engine\n",
    "This function will help us easily create `AIEngine` instances for our agent and worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_ai_engine(default_provider: str = \"openai\", model: Optional[str] = None) -> Optional[AIEngine]:\n",
    "    \"\"\"Creates and initializes an AI Engine with the specified provider.\"\"\"\n",
    "    config_dict = {\n",
    "        \"default_provider\": None,\n",
    "        \"log_prompts\": True,\n",
    "        \"log_responses\": True,\n",
    "        \"providers\": {}\n",
    "    }\n",
    "\n",
    "    if api_keys_available[\"openai\"]:\n",
    "        config_dict[\"providers\"][\"openai\"] = {\n",
    "            \"api_key\": OPENAI_API_KEY,\n",
    "            \"default_model\": model if model and default_provider == \"openai\" else \"gpt-4o-mini\",\n",
    "            \"default_temperature\": 0.7,\n",
    "            \"timeout\": 60,\n",
    "            \"enabled\": True\n",
    "        }\n",
    "        if not config_dict[\"default_provider\"]:\n",
    "             config_dict[\"default_provider\"] = \"openai\"\n",
    "\n",
    "    if api_keys_available[\"anthropic\"]:\n",
    "        config_dict[\"providers\"][\"anthropic\"] = {\n",
    "            \"api_key\": ANTHROPIC_API_KEY,\n",
    "            \"default_model\": model if model and default_provider == \"anthropic\" else \"claude-3-haiku-20240307\",\n",
    "            \"default_temperature\": 0.7,\n",
    "            \"timeout\": 60,\n",
    "            \"enabled\": True\n",
    "        }\n",
    "        if not config_dict[\"default_provider\"]:\n",
    "            config_dict[\"default_provider\"] = \"anthropic\"\n",
    "    \n",
    "    # Override default provider if specified and available\n",
    "    if default_provider in config_dict[\"providers\"] and config_dict[\"providers\"][default_provider][\"enabled\"]:\n",
    "        config_dict[\"default_provider\"] = default_provider\n",
    "    elif not config_dict[\"default_provider\"]:\n",
    "        print(f\"Warning: Specified default provider '{default_provider}' is not available or configured.\")\n",
    "        print(f\"No API keys available to create an AI Engine.\")\n",
    "        return None\n",
    "\n",
    "    ai_config = AIConfig(**config_dict)\n",
    "    engine = AIEngine(config=ai_config)\n",
    "    await engine.initialize()\n",
    "    print(f\"AI Engine created with default provider: {engine.config.default_provider} using model {engine.get_default_model()}\\n\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Pydantic Models for Structured Output\n",
    "\n",
    "We'll use Pydantic models to define the expected structure of the data returned by our Task Worker and the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefinedQueryComponents(BaseModel):\n",
    "    \"\"\"Structure for components refined by the Task Worker.\"\"\"\n",
    "    main_goal: str = Field(description=\"The core objective of the request.\")\n",
    "    key_elements_to_include: List[str] = Field(description=\"Specific elements or topics that must be part of the response.\")\n",
    "    target_audience: Optional[str] = Field(default=None, description=\"The intended audience for the final output.\")\n",
    "    desired_tone: Optional[str] = Field(default=None, description=\"The preferred tone or style of the response (e.g., formal, creative, humorous).\")\n",
    "    constraints_or_exclusions: List[str] = Field(default_factory=list, description=\"Any constraints or topics to avoid.\")\n",
    "\n",
    "class FinalContentOutput(BaseModel):\n",
    "    \"\"\"Structure for the final content generated by the Initial Agent.\"\"\"\n",
    "    title: str = Field(description=\"A suitable title for the generated content.\")\n",
    "    content_body: str = Field(description=\"The main body of the generated content.\")\n",
    "    suggestions_for_next_steps: Optional[List[str]] = Field(default=None, description=\"Optional suggestions for how to use or extend this content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Task Worker\n",
    "\n",
    "The `TaskWorker` will take an initial, potentially vague, user query. Its job is to use its AI engine to break down this query into more structured components, making it easier for the `InitialAgent` to formulate a high-quality prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskWorker:\n",
    "    \"\"\"A worker that refines a user query into structured components.\"\"\"\n",
    "    def __init__(self, ai_engine: AIEngine):\n",
    "        self.ai_engine = ai_engine\n",
    "        if not self.ai_engine:\n",
    "            raise ValueError(\"TaskWorker requires a valid AIEngine instance.\")\n",
    "\n",
    "    async def refine_query(self, user_query: str) -> Optional[RefinedQueryComponents]:\n",
    "        \"\"\"Uses AI to refine the user query into structured components.\"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are an expert query analyst. Your task is to take a user's request and break it down \"\n",
    "            \"into structured components that will help another AI generate a high-quality response. \"\n",
    "            \"Identify the main goal, key elements to include, target audience (if inferable), desired tone (if inferable), \"\n",
    "            \"and any implicit constraints or items to exclude.\"\n",
    "        )\n",
    "        \n",
    "        prompt = f\"Analyze the following user request and extract its structured components:\\n\\nUser Request: {user_query}\"\n",
    "        \n",
    "        print(f\"\\nðŸ¤– Task Worker: Refining query - '{user_query[:50]}...'\\n\")\n",
    "        try:\n",
    "            response = await self.ai_engine.generate_structured(\n",
    "                system=system_prompt,\n",
    "                user=prompt,\n",
    "                output_schema=RefinedQueryComponents\n",
    "            )\n",
    "            if response and response.output:\n",
    "                print(\"\\nðŸ¤– Task Worker: Query refined successfully.\")\n",
    "                pprint(response.output.model_dump(), indent=2)\n",
    "                return response.output\n",
    "            else:\n",
    "                print(\"\\nðŸ¤– Task Worker: Failed to get structured output for query refinement.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"\\nðŸ¤– Task Worker: Error during query refinement - {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Initial Agent\n",
    "\n",
    "The `InitialAgent` receives a high-level goal. It first delegates to the `TaskWorker` to get refined query components. Then, it uses these components to construct a detailed prompt for its own AI engine to generate the final desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitialAgent:\n",
    "    \"\"\"An agent that uses a TaskWorker to refine prompts before execution.\"\"\"\n",
    "    def __init__(self, ai_engine: AIEngine, task_worker: TaskWorker):\n",
    "        self.ai_engine = ai_engine\n",
    "        self.task_worker = task_worker\n",
    "        if not self.ai_engine or not self.task_worker:\n",
    "            raise ValueError(\"InitialAgent requires valid AIEngine and TaskWorker instances.\")\n",
    "\n",
    "    def _construct_final_prompt(self, refined_components: RefinedQueryComponents) -> str:\n",
    "        \"\"\"Constructs a detailed final prompt from refined components.\"\"\"\n",
    "        prompt_parts = [\n",
    "            f\"Objective: {refined_components.main_goal}\",\n",
    "            \"\\nKey Elements to Incorporate:\",\n",
    "            *[\"- \" + item for item in refined_components.key_elements_to_include],\n",
    "        ]\n",
    "        if refined_components.target_audience:\n",
    "            prompt_parts.append(f\"\\nTarget Audience: {refined_components.target_audience}\")\n",
    "        if refined_components.desired_tone:\n",
    "            prompt_parts.append(f\"\\nDesired Tone: {refined_components.desired_tone}\")\n",
    "        if refined_components.constraints_or_exclusions:\n",
    "            prompt_parts.append(\"\\nConstraints/Exclusions:\")\n",
    "            prompt_parts.extend([\"- \" + item for item in refined_components.constraints_or_exclusions])\n",
    "        \n",
    "        prompt_parts.append(\"\\nPlease generate the content based on these detailed instructions.\")\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    async def process_goal(self, user_goal: str) -> Optional[FinalContentOutput]:\n",
    "        \"\"\"Processes a user goal by delegating refinement and then generating content.\"\"\"\n",
    "        print(f\"\\nðŸš€ Initial Agent: Received goal - '{user_goal[:50]}...'\\n\")\n",
    "        \n",
    "        # 1. Delegate to Task Worker for query refinement\n",
    "        refined_components = await self.task_worker.refine_query(user_goal)\n",
    "        if not refined_components:\n",
    "            print(\"\\nðŸš€ Initial Agent: Could not get refined components from Task Worker. Aborting.\")\n",
    "            return None\n",
    "        \n",
    "        # 2. Construct the final detailed prompt\n",
    "        final_prompt = self._construct_final_prompt(refined_components)\n",
    "        print(\"\\nðŸš€ Initial Agent: Constructed final prompt:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(final_prompt)\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # 3. Use own AI engine to generate the final output\n",
    "        system_prompt_final_generation = (\n",
    "            \"You are a creative content generation AI. Your task is to produce high-quality content \"\n",
    "            \"based on the detailed instructions provided. Ensure the output is well-structured and engaging.\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\nðŸš€ Initial Agent: Generating final content...\")\n",
    "        try:\n",
    "            response = await self.ai_engine.generate_structured(\n",
    "                system=system_prompt_final_generation,\n",
    "                user=final_prompt,\n",
    "                output_schema=FinalContentOutput\n",
    "            )\n",
    "            if response and response.output:\n",
    "                print(\"\\nðŸš€ Initial Agent: Final content generated successfully.\")\n",
    "                pprint(response.output.model_dump(), indent=2)\n",
    "                return response.output\n",
    "            else:\n",
    "                print(\"\\nðŸš€ Initial Agent: Failed to get structured output for final content generation.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"\\nðŸš€ Initial Agent: Error during final content generation - {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demonstration\n",
    "\n",
    "Let's instantiate the agent and worker and see them in action. We'll provide a sample high-level goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create AI engines for worker and agent\n",
    "    # You might use different models or configurations for each\n",
    "    worker_ai_engine = await create_ai_engine(default_provider=\"openai\", model=\"gpt-4o-mini\") # Worker might use a faster/cheaper model for analysis\n",
    "    agent_ai_engine = await create_ai_engine(default_provider=\"openai\", model=\"gpt-4o-mini\")  # Agent might use a more powerful model for generation\n",
    "\n",
    "    if not worker_ai_engine or not agent_ai_engine:\n",
    "        print(\"Could not create AI engines. Ensure API keys are set and providers are available. Aborting demonstration.\")\n",
    "        return\n",
    "\n",
    "    # Instantiate worker and agent\n",
    "    task_worker_instance = TaskWorker(ai_engine=worker_ai_engine)\n",
    "    initial_agent_instance = InitialAgent(ai_engine=agent_ai_engine, task_worker=task_worker_instance)\n",
    "\n",
    "    # Define a sample user goal\n",
    "    user_goal = \"I need a short blog post about the benefits of remote work for small businesses, targeting entrepreneurs who are hesitant to adopt it. Make it encouraging but also acknowledge potential challenges briefly.\"\n",
    "    \n",
    "    # Process the goal\n",
    "    final_output = await initial_agent_instance.process_goal(user_goal)\n",
    "    \n",
    "    if final_output:\n",
    "        print(\"\\nðŸŽ‰ Demonstration Complete! Final Output:\")\n",
    "        # Output is already pretty-printed by the agent, but we can show specific parts here if needed\n",
    "        # print(f\"Title: {final_output.title}\")\n",
    "        # print(f\"Content: {final_output.content_body[:200]}...\")\n",
    "    else:\n",
    "        print(\"\\nðŸ˜” Demonstration Failed to produce final output.\")\n",
    "    \n",
    "    # Clean up AI Engines (if they have a shutdown method)\n",
    "    if hasattr(worker_ai_engine, 'shutdown'):\n",
    "        await worker_ai_engine.shutdown()\n",
    "    if hasattr(agent_ai_engine, 'shutdown'):\n",
    "        await agent_ai_engine.shutdown()\n",
    "\n",
    "# Run the demonstration\n",
    "# Ensure you have an event loop running if you are in a script.\n",
    "# In Jupyter, this will typically run fine.\n",
    "if __name__ == '__main__':\n",
    "    # In a .py script, you would run asyncio.run(main())\n",
    "    # In Jupyter, we can often await main() directly if the loop is managed, \n",
    "    # or use nest_asyncio if needed, but let's try direct await for simplicity first.\n",
    "    # For robust execution in Jupyter, especially if other async code is running:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook demonstrated a task delegation pattern where an `InitialAgent` leverages a `TaskWorker` to refine a user's request into a more structured and detailed set of components. This allows the `InitialAgent` to construct a higher-quality prompt for its own AI engine, leading to better final outputs.\n",
    "\n",
    "**Benefits of this pattern:**\n",
    "- **Improved Prompt Quality**: Breaking down the task allows for more focused and detailed prompt engineering.\n",
    "- **Modularity**: The worker and agent can be developed and scaled independently. Different workers could specialize in different types of refinement.\n",
    "- **Specialization**: The worker's AI can be optimized (e.g., different model, specific system prompt) for analytical/refinement tasks, while the agent's AI can be optimized for generative tasks.\n",
    "- **Reduced Cognitive Load on Agent**: The agent doesn't need to handle the initial ambiguity directly; it receives a more structured input.\n",
    "- **Potential for Cost Optimization**: The refinement task might be achievable with a less powerful (and cheaper) LLM, reserving the more powerful LLM for the final generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}