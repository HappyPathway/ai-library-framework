{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Agent Communication and Coordination with AILF ZeroMQ Utilities\n",
                "\n",
                "This notebook demonstrates how multiple agents can communicate and coordinate using the `ailf.messaging.zmq` utilities to accomplish a common, distributed task. We'll implement a simple pipeline pattern:\n",
                "\n",
                "1.  **Task Generator Agent**: Creates tasks and distributes them.\n",
                "2.  **Task Processor Agent(s)**: Receive tasks, perform simulated work, and send back results.\n",
                "3.  **Result Collector Agent**: Gathers results from the processor agents.\n",
                "\n",
                "This example uses ZMQ's PUSH/PULL socket types via the `ZMQPush` and `ZMQPull` classes from `ailf.messaging.zmq`, which are well-suited for task distribution and collection pipelines."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup\n",
                "\n",
                "Import necessary libraries. We'll use `ailf.messaging.zmq` utilities for ZeroMQ communication patterns, along with `threading` to run agents concurrently, `time` for simulating work, and `uuid` for unique task IDs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "import threading\n",
                "import uuid\n",
                "import json\n",
                "from typing import Dict, Any, Union\n",
                "\n",
                "# Try to import ailf.messaging; fall back to raw zmq if not installed\n",
                "try:\n",
                "    import zmq\n",
                "    from ailf.messaging import (\n",
                "        ZMQPush, \n",
                "        ZMQPull, \n",
                "        ZMQPublisher, \n",
                "        ZMQSubscriber\n",
                "    )\n",
                "    print(f\"Using AILF Messaging ZMQ utilities with PyZMQ version: {zmq.pyzmq_version()}\")\n",
                "    using_ailf = True\n",
                "except ImportError:\n",
                "    # Fallback to raw ZMQ if AILF is not installed\n",
                "    import zmq\n",
                "    print(f\"AILF Messaging not found. Using raw PyZMQ version: {zmq.pyzmq_version()}\")\n",
                "    print(f\"To install AILF Messaging, run: pip install -e /workspaces/template-python-dev\")\n",
                "    using_ailf = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_zmq_push(context=None, use_ailf=True):\n",
                "    \"\"\"Create a PUSH socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf:\n",
                "        return ZMQPush(context)\n",
                "    else:\n",
                "        socket = context.socket(zmq.PUSH) if context else zmq.Context.instance().socket(zmq.PUSH)\n",
                "        return socket\n",
                "\n",
                "def create_zmq_pull(context=None, use_ailf=True):\n",
                "    \"\"\"Create a PULL socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf:\n",
                "        return ZMQPull(context)\n",
                "    else:\n",
                "        socket = context.socket(zmq.PULL) if context else zmq.Context.instance().socket(zmq.PULL)\n",
                "        return socket\n",
                "        \n",
                "def create_zmq_pub(context=None, use_ailf=True):\n",
                "    \"\"\"Create a PUB socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf:\n",
                "        return ZMQPublisher(context)\n",
                "    else:\n",
                "        socket = context.socket(zmq.PUB) if context else zmq.Context.instance().socket(zmq.PUB)\n",
                "        return socket\n",
                "        \n",
                "def create_zmq_sub(context=None, use_ailf=True):\n",
                "    \"\"\"Create a SUB socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf:\n",
                "        return ZMQSubscriber(context)\n",
                "    else:\n",
                "        socket = context.socket(zmq.SUB) if context else zmq.Context.instance().socket(zmq.SUB)\n",
                "        return socket\n",
                "        \n",
                "def send_json(socket, data, use_ailf=True):\n",
                "    \"\"\"Send JSON data using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf and hasattr(socket, 'push_json'):\n",
                "        socket.push_json(data)\n",
                "    elif use_ailf and using_ailf and hasattr(socket, 'publish'):\n",
                "        socket.publish('', data)  # Empty topic for broadcast\n",
                "    elif hasattr(socket, 'send_json'):\n",
                "        socket.send_json(data)\n",
                "    else:\n",
                "        socket.send(json.dumps(data).encode('utf-8'))\n",
                "        \n",
                "def recv_json(socket, use_ailf=True):\n",
                "    \"\"\"Receive JSON data using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf and hasattr(socket, 'pull_json'): # For ZMQPull\n",
                "        return socket.pull_json()\n",
                "    elif use_ailf and using_ailf and hasattr(socket, 'receive'): # For ZMQSubscriber\n",
                "        # AILF's ZMQSubscriber.receive() returns (topic, message)\n",
                "        # The message might already be deserialized by AILF if it was JSON.\n",
                "        _topic, received_message = socket.receive()\n",
                "        \n",
                "        if isinstance(received_message, (dict, list)):\n",
                "            # Message is already a Python dict/list (deserialized by AILF)\n",
                "            return received_message\n",
                "        elif isinstance(received_message, str):\n",
                "            # Message is a string, attempt to parse as JSON\n",
                "            try:\n",
                "                return json.loads(received_message)\n",
                "            except json.JSONDecodeError as e:\n",
                "                raise ValueError(f\"Failed to decode JSON string from AILF subscriber: {received_message}\") from e\n",
                "        elif isinstance(received_message, bytes):\n",
                "            # Message is bytes, attempt to decode UTF-8 then parse as JSON\n",
                "            try:\n",
                "                return json.loads(received_message.decode('utf-8'))\n",
                "            except (json.JSONDecodeError, UnicodeDecodeError) as e:\n",
                "                raise ValueError(f\"Failed to decode JSON bytes from AILF subscriber: {received_message}\") from e\n",
                "        else:\n",
                "            # Unexpected message type\n",
                "            raise TypeError(f\"Unexpected message type from AILF subscriber: {type(received_message)}, value: {received_message}\")\n",
                "    elif hasattr(socket, 'recv_json'): # Raw ZMQ with built-in json support\n",
                "        return socket.recv_json()\n",
                "    else: # Raw ZMQ, manual deserialization\n",
                "        data = socket.recv()\n",
                "        try:\n",
                "            return json.loads(data.decode('utf-8'))\n",
                "        except (json.JSONDecodeError, UnicodeDecodeError) as e:\n",
                "            raise ValueError(f\"Failed to decode JSON from raw ZMQ socket: {data}\") from e\n",
                "        \n",
                "def bind_socket(socket, address, use_ailf=True):\n",
                "    \"\"\"Bind socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf and hasattr(socket, 'bind'):\n",
                "        socket.bind(address)\n",
                "    else:\n",
                "        socket.bind(address)\n",
                "        \n",
                "def connect_socket(socket, address, use_ailf=True):\n",
                "    \"\"\"Connect socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf and hasattr(socket, 'connect'):\n",
                "        socket.connect(address)\n",
                "    else:\n",
                "        socket.connect(address)\n",
                "        \n",
                "def subscribe_topic(socket, topic, use_ailf=True):\n",
                "    \"\"\"Subscribe to topic using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf and hasattr(socket, 'subscribe'):\n",
                "        socket.subscribe(topic)\n",
                "    else:\n",
                "        socket.setsockopt(zmq.SUBSCRIBE, topic.encode('utf-8') if isinstance(topic, str) else topic)\n",
                "        \n",
                "def close_socket(socket, use_ailf=True):\n",
                "    \"\"\"Close socket using either AILF or raw ZMQ.\"\"\"\n",
                "    if use_ailf and using_ailf and hasattr(socket, 'close'):\n",
                "        socket.close()\n",
                "    elif hasattr(socket, 'close'):\n",
                "        socket.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ZMQ Configuration and Message Structures\n",
                "\n",
                "Define the network addresses for our ZMQ sockets and simple structures for messages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Addresses for ZMQ sockets\n",
                "TASK_VENTILATOR_ADDR = \"tcp://127.0.0.1:5557\"  # For sending tasks from generator to processors\n",
                "RESULT_COLLECTOR_ADDR = \"tcp://127.0.0.1:5558\" # For sending results from processors to collector\n",
                "CONTROL_SYNC_ADDR = \"tcp://127.0.0.1:5559\" # For synchronizing start of workers\n",
                "\n",
                "# Message structure examples (can be formalized with Pydantic if needed)\n",
                "def create_task_message(data: Any) -> Dict[str, Any]:\n",
                "    return {\"task_id\": str(uuid.uuid4()), \"data\": data, \"timestamp\": time.time()}\n",
                "\n",
                "def create_result_message(task_id: str, result_data: Any, worker_id: str) -> Dict[str, Any]:\n",
                "    return {\"task_id\": task_id, \"result_data\": result_data, \"worker_id\": worker_id, \"timestamp\": time.time()}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Agent Implementations\n",
                "\n",
                "We'll define wrapper functions to handle the two different implementations (AILF ZMQ or raw ZMQ), and then define our agent functions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Task Generator Agent\n",
                "\n",
                "This agent generates a specified number of tasks and PUSHes them to the Task Processor agents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def task_generator_agent(num_tasks: int, num_workers: int, use_ailf: bool = True):\n",
                "    \"\"\"Generates tasks and sends them to processor agents.\"\"\"\n",
                "    context = zmq.Context()\n",
                "    \n",
                "    # Socket to send messages on (PUSH)\n",
                "    ventilator_socket = create_zmq_push(context, use_ailf)\n",
                "    bind_socket(ventilator_socket, TASK_VENTILATOR_ADDR, use_ailf)\n",
                "    print(f\"[Generator] Task ventilator bound to {TASK_VENTILATOR_ADDR}\")\n",
                "\n",
                "    # Socket for worker synchronization (PUB)\n",
                "    sync_socket = create_zmq_pub(context, use_ailf)\n",
                "    bind_socket(sync_socket, CONTROL_SYNC_ADDR, use_ailf)\n",
                "    print(f\"[Generator] Sync service bound to {CONTROL_SYNC_ADDR}\")\n",
                "\n",
                "    # Wait for all workers to connect (simple sync)\n",
                "    print(f\"[Generator] Waiting for {num_workers} worker(s) to be ready...\")\n",
                "    time.sleep(num_workers * 0.5 + 1) # Give workers time to start and connect\n",
                "    \n",
                "    # Send synchronization signal to all workers\n",
                "    print(\"[Generator] Sending start signal to workers.\")\n",
                "    if use_ailf and using_ailf and hasattr(sync_socket, 'publish'):\n",
                "        sync_socket.publish(\"START\", \"\")\n",
                "    else:\n",
                "        sync_socket.send_string(\"START\")\n",
                "\n",
                "    print(f\"[Generator] Starting to send {num_tasks} tasks...\")\n",
                "    for i in range(num_tasks):\n",
                "        task_data = f\"Task_{i+1}_payload\"\n",
                "        message = create_task_message(task_data)\n",
                "        send_json(ventilator_socket, message, use_ailf)\n",
                "        print(f\"[Generator] Sent task: {message['task_id']} ({task_data})\")\n",
                "        time.sleep(0.1)  # Simulate some delay between sending tasks\n",
                "    \n",
                "    # Send a sentinel value to indicate end of tasks for each worker\n",
                "    for _ in range(num_workers):\n",
                "        send_json(ventilator_socket, {\"task_id\": \"END_OF_TASKS\", \"data\": None}, use_ailf)\n",
                "        print(\"[Generator] Sent END_OF_TASKS signal.\")\n",
                "\n",
                "    print(\"[Generator] All tasks sent. Closing sockets.\")\n",
                "    close_socket(ventilator_socket, use_ailf)\n",
                "    close_socket(sync_socket, use_ailf)\n",
                "    context.term()\n",
                "    print(\"[Generator] Finished.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Task Processor Agent\n",
                "\n",
                "This agent (of which there can be multiple instances) PULLs tasks, simulates processing, and PUSHes results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def task_processor_agent(worker_id: str, use_ailf: bool = True):\n",
                "    \"\"\"Receives tasks, processes them, and sends results.\"\"\"\n",
                "    context = zmq.Context()\n",
                "    \n",
                "    # Socket to receive messages from (PULL)\n",
                "    receiver_socket = create_zmq_pull(context, use_ailf)\n",
                "    connect_socket(receiver_socket, TASK_VENTILATOR_ADDR, use_ailf)\n",
                "    print(f\"[Worker-{worker_id}] Connected to task ventilator at {TASK_VENTILATOR_ADDR}\")\n",
                "\n",
                "    # Socket to send results to (PUSH)\n",
                "    results_sender_socket = create_zmq_push(context, use_ailf)\n",
                "    connect_socket(results_sender_socket, RESULT_COLLECTOR_ADDR, use_ailf)\n",
                "    print(f\"[Worker-{worker_id}] Connected to result collector at {RESULT_COLLECTOR_ADDR}\")\n",
                "\n",
                "    # Socket to receive synchronization signal (SUB)\n",
                "    sync_subscriber = create_zmq_sub(context, use_ailf)\n",
                "    connect_socket(sync_subscriber, CONTROL_SYNC_ADDR, use_ailf)\n",
                "    subscribe_topic(sync_subscriber, \"START\", use_ailf)\n",
                "    print(f\"[Worker-{worker_id}] Subscribed to sync service at {CONTROL_SYNC_ADDR}\")\n",
                "\n",
                "    # Wait for the start signal\n",
                "    print(f\"[Worker-{worker_id}] Waiting for start signal...\")\n",
                "    if use_ailf and using_ailf and hasattr(sync_subscriber, 'receive'):\n",
                "        topic, _ = sync_subscriber.receive()\n",
                "        sync_message = topic  # In AILF, the topic is the message for simple string messages\n",
                "    else:\n",
                "        sync_message = sync_subscriber.recv_string()\n",
                "        \n",
                "    if sync_message == \"START\":\n",
                "        print(f\"[Worker-{worker_id}] Received START signal. Beginning task processing.\")\n",
                "    else:\n",
                "        print(f\"[Worker-{worker_id}] Received unexpected sync message: {sync_message}. Exiting.\")\n",
                "        close_socket(receiver_socket, use_ailf)\n",
                "        close_socket(results_sender_socket, use_ailf)\n",
                "        close_socket(sync_subscriber, use_ailf)\n",
                "        context.term()\n",
                "        return\n",
                "\n",
                "    while True:\n",
                "        try:\n",
                "            task_message = recv_json(receiver_socket, use_ailf)\n",
                "            task_id = task_message.get(\"task_id\")\n",
                "            \n",
                "            if task_id == \"END_OF_TASKS\":\n",
                "                print(f\"[Worker-{worker_id}] Received END_OF_TASKS. Shutting down.\")\n",
                "                # Forward the END_OF_TASKS signal to the collector so it knows this worker is done\n",
                "                send_json(results_sender_socket, {\"task_id\": \"WORKER_DONE\", \"worker_id\": worker_id}, use_ailf)\n",
                "                break\n",
                "            \n",
                "            task_data = task_message.get(\"data\")\n",
                "            print(f\"[Worker-{worker_id}] Received task: {task_id} ({task_data})\")\n",
                "            \n",
                "            # Simulate work\n",
                "            processing_time = 0.5 + (int(worker_id) * 0.1) # Vary processing time slightly per worker\n",
                "            time.sleep(processing_time)\n",
                "            result_data = f\"Result_for_({task_data})_by_Worker-{worker_id}\"\n",
                "            \n",
                "            result_message = create_result_message(task_id, result_data, worker_id)\n",
                "            send_json(results_sender_socket, result_message, use_ailf)\n",
                "            print(f\"[Worker-{worker_id}] Sent result for task: {task_id}\")\n",
                "            \n",
                "        except zmq.error.ContextTerminated:\n",
                "            print(f\"[Worker-{worker_id}] Context terminated, exiting loop.\")\n",
                "            break\n",
                "        except Exception as e:\n",
                "            print(f\"[Worker-{worker_id}] Error processing task: {e}\")\n",
                "            break # Exit on error for simplicity\n",
                "\n",
                "    print(f\"[Worker-{worker_id}] Closing sockets.\")\n",
                "    close_socket(receiver_socket, use_ailf)\n",
                "    close_socket(results_sender_socket, use_ailf)\n",
                "    close_socket(sync_subscriber, use_ailf)\n",
                "    context.term()\n",
                "    print(f\"[Worker-{worker_id}] Finished.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Result Collector Agent\n",
                "\n",
                "This agent PULLs results from the Task Processor agents and prints them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def result_collector_agent(num_expected_tasks: int, num_workers: int, use_ailf: bool = True):\n",
                "    \"\"\"Collects results from processor agents.\"\"\"\n",
                "    context = zmq.Context()\n",
                "    \n",
                "    # Socket to receive results on (PULL)\n",
                "    results_receiver_socket = create_zmq_pull(context, use_ailf)\n",
                "    bind_socket(results_receiver_socket, RESULT_COLLECTOR_ADDR, use_ailf)\n",
                "    print(f\"[Collector] Result collector bound to {RESULT_COLLECTOR_ADDR}\")\n",
                "\n",
                "    collected_results = []\n",
                "    workers_done_count = 0\n",
                "\n",
                "    print(f\"[Collector] Waiting for results... Expected {num_expected_tasks} task results and {num_workers} worker done signals.\")\n",
                "    \n",
                "    # We expect num_expected_tasks results + num_workers WORKER_DONE signals\n",
                "    total_expected_messages = num_expected_tasks + num_workers\n",
                "    received_messages = 0\n",
                "\n",
                "    while received_messages < total_expected_messages:\n",
                "        try:\n",
                "            result_message = recv_json(results_receiver_socket, use_ailf)\n",
                "            received_messages += 1\n",
                "            task_id = result_message.get(\"task_id\")\n",
                "\n",
                "            if task_id == \"WORKER_DONE\":\n",
                "                workers_done_count += 1\n",
                "                print(f\"[Collector] Worker {result_message.get('worker_id')} reported done. ({workers_done_count}/{num_workers} workers done)\")\n",
                "            else:\n",
                "                collected_results.append(result_message)\n",
                "                print(f\"[Collector] Received result for task: {task_id} from Worker-{result_message.get('worker_id')}. Data: {result_message.get('result_data')}\")\n",
                "            \n",
                "        except zmq.error.ContextTerminated:\n",
                "            print(\"[Collector] Context terminated, exiting loop.\")\n",
                "            break\n",
                "        except Exception as e:\n",
                "            print(f\"[Collector] Error receiving result: {e}\")\n",
                "            break # Exit on error for simplicity\n",
                "\n",
                "    print(f\"\\n[Collector] --- Summary ---\")\n",
                "    print(f\"[Collector] Collected {len(collected_results)} results out of {num_expected_tasks} expected task results.\")\n",
                "    print(f\"[Collector] {workers_done_count} workers reported done.\")\n",
                "    # for res in collected_results:\n",
                "    #     print(f\"  - Task {res['task_id']}: {res['result_data']} (from Worker-{res['worker_id']})\")\n",
                "    \n",
                "    print(\"[Collector] Closing socket.\")\n",
                "    close_socket(results_receiver_socket, use_ailf)\n",
                "    context.term()\n",
                "    print(\"[Collector] Finished.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Orchestration and Demonstration\n",
                "\n",
                "Now, let's run these agents concurrently using threads."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_demo(use_ailf: bool = True):\n",
                "    \"\"\"Run the multi-agent ZMQ demonstration.\n",
                "    \n",
                "    Args:\n",
                "        use_ailf: Whether to use AILF ZMQ utilities (if available)\n",
                "    \"\"\"\n",
                "    NUM_TASKS_TO_GENERATE = 10\n",
                "    NUM_PROCESSOR_WORKERS = 2\n",
                "\n",
                "    implementation = \"AILF ZMQ utilities\" if use_ailf and using_ailf else \"raw ZMQ\"\n",
                "    print(f\"--- Starting Multi-Agent {implementation} Demonstration ---\")\n",
                "\n",
                "    # Create threads for each agent\n",
                "    collector_thread = threading.Thread(\n",
                "        target=result_collector_agent, \n",
                "        args=(NUM_TASKS_TO_GENERATE, NUM_PROCESSOR_WORKERS, use_ailf)\n",
                "    )\n",
                "    \n",
                "    worker_threads = []\n",
                "    for i in range(NUM_PROCESSOR_WORKERS):\n",
                "        worker_id = str(i + 1)\n",
                "        thread = threading.Thread(\n",
                "            target=task_processor_agent, \n",
                "            args=(worker_id, use_ailf)\n",
                "        )\n",
                "        worker_threads.append(thread)\n",
                "        \n",
                "    generator_thread = threading.Thread(\n",
                "        target=task_generator_agent, \n",
                "        args=(NUM_TASKS_TO_GENERATE, NUM_PROCESSOR_WORKERS, use_ailf)\n",
                "    )\n",
                "\n",
                "    # Start threads\n",
                "    print(\"\\nStarting Result Collector Agent...\")\n",
                "    collector_thread.start()\n",
                "    \n",
                "    time.sleep(0.5) # Give collector a moment to bind\n",
                "\n",
                "    print(\"\\nStarting Task Processor Agents...\")\n",
                "    for thread in worker_threads:\n",
                "        thread.start()\n",
                "        \n",
                "    time.sleep(1) # Give workers time to connect to sync service\n",
                "\n",
                "    print(\"\\nStarting Task Generator Agent...\")\n",
                "    generator_thread.start()\n",
                "\n",
                "    # Wait for all threads to complete\n",
                "    print(\"\\nWaiting for agents to finish...\")\n",
                "    generator_thread.join()\n",
                "    print(\"Generator agent joined.\")\n",
                "    for thread in worker_threads:\n",
                "        thread.join()\n",
                "    print(\"All worker agents joined.\")\n",
                "    collector_thread.join()\n",
                "    print(\"Collector agent joined.\")\n",
                "\n",
                "    print(f\"\\n--- Multi-Agent {implementation} Demonstration Complete ---\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # Prefer using AILF ZMQ utilities if available, otherwise fall back to raw ZMQ\n",
                "    run_demo(use_ailf=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Conclusion\n",
                "\n",
                "This notebook demonstrated a basic multi-agent system using AILF's ZeroMQ utilities for communication and coordination. We saw:\n",
                "\n",
                "- A **Task Generator** distributing work using a ZMQPush socket.\n",
                "- Multiple **Task Processors** receiving work via ZMQPull sockets, processing it, and sending results via ZMQPush sockets.\n",
                "- A **Result Collector** gathering results using a ZMQPull socket.\n",
                "- A simple synchronization mechanism using ZMQPublisher/ZMQSubscriber to coordinate the start of workers.\n",
                "- Fallback to raw ZMQ when AILF messaging utilities are not available.\n",
                "\n",
                "**Advantages of Using AILF Messaging:**\n",
                "\n",
                "1. **Abstraction**: Higher-level abstractions over ZeroMQ operations\n",
                "2. **Resource Management**: Automatic resource cleanup and better error handling\n",
                "3. **Type Safety**: Method signatures provide better guidance on usage\n",
                "4. **Consistent API**: Uniform interface for different messaging patterns\n",
                "5. **Integration**: Seamless integration with other AILF components like logging and monitoring\n",
                "\n",
                "**Potential Extensions:**\n",
                "\n",
                "- **Error Handling**: Implementing more robust error handling using AILF's logging mechanisms\n",
                "- **Monitoring**: Adding metrics collection for performance and reliability\n",
                "- **Dynamic Workers**: Creating workers that can join and leave the pool dynamically\n",
                "- **Complex Task Payloads**: Using Pydantic models for structured message validation\n",
                "- **Integration with AI Logic**: Each `task_processor_agent` could internally use an AI engine (like `AIEngine`) from the AILF framework to perform its task\n",
                "\n",
                "The AILF messaging utilities provide a robust foundation for building distributed agent systems without the need to handle many of the low-level ZeroMQ details directly."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
